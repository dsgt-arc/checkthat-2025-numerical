{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm   \n",
    "import torch\n",
    "import pacmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda mps or cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../../data\")\n",
    "train_claims_file = Path(\"train_claims_quantemp.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_claims = pl.read_json(data_dir / train_claims_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str length stats of doc and claim \n",
    "train_claims['doc'].str.len_chars().describe().rename({\"value\": \"docs\"}).join(train_claims['claim'].str.len_chars().describe().rename({\"value\": \"claim\"}), on='statistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform/encode labels\n",
    "LE = LabelEncoder()\n",
    "# Fit and transform the 'label' column\n",
    "label_encoded = LE.fit_transform(train_claims[\"label\"].to_list())\n",
    "\n",
    "# Add the encoded labels as a new column\n",
    "train_claims = train_claims.with_columns(\n",
    "    pl.Series(name=\"label_encoded\", values=label_encoded)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"answerdotai/ModernBERT-base\"\n",
    "\n",
    "# context window size\n",
    "if model in [\"answerdotai/ModernBERT-base\", \"answerdotai/ModernBERT-large\"]:\n",
    "    context_window = 128 #8192 is max -> evidence. 128 is for claim\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "model = AutoModel.from_pretrained(model).to(device)\n",
    "\n",
    "\n",
    "# Base configuration for encode_plus\n",
    "base_config = {\n",
    "    'add_special_tokens': True,\n",
    "    'padding': 'max_length',\n",
    "    'truncation': True,\n",
    "    'return_attention_mask': True,\n",
    "    'return_tensors': 'pt',\n",
    "    'pad_to_max_length': True,\n",
    "    'max_length': context_window,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and encode documents\n",
    "encoded = list()\n",
    "for sequence in tqdm(train_claims['claim']):\n",
    "    encoded.append(\n",
    "        tokenizer.encode_plus(sequence, **base_config)\n",
    "        .to(device)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When embedding evidence, cannot use batch_size > 1 due to long context window\n",
    "batch_size = 20\n",
    "dataloader = DataLoader(\n",
    "            encoded,\n",
    "            batch_size = batch_size,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "cls_embeddings = []\n",
    "\n",
    "# Iterate through batches in DataLoader\n",
    "for batch in tqdm(dataloader):\n",
    "    # Move batch to GPU\n",
    "    b_input_ids = batch['input_ids'].reshape(-1, context_window)\n",
    "    b_input_mask = batch['attention_mask'].reshape(-1, context_window)\n",
    "    # Perform forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids, b_input_mask)\n",
    "        # Extract the CLS token embeddings from the last hidden state\n",
    "        cls_embeddings.append(outputs.last_hidden_state[:, 0, :].cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the list of arrays into a single NumPy array\n",
    "cls_embeddings_np = np.concatenate(cls_embeddings)\n",
    "\n",
    "# Add the new column to the original DataFrame\n",
    "embedding_df = pl.DataFrame({\"claim_embedding\": cls_embeddings_np.tolist()})\n",
    "train_claims = train_claims.with_columns(embedding_df[\"claim_embedding\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality Reduction PacMAP, UMAP, t-SNE\n",
    "\n",
    "# initializing the pacmap instance\n",
    "# Setting n_neighbors to \"None\" leads to an automatic choice shown below in \"parameter\" section\n",
    "embedding = pacmap.PaCMAP(n_components=2, n_neighbors=10, MN_ratio=0.5, FP_ratio=2.0) \n",
    "\n",
    "claim_embedding_reduced = embedding.fit_transform(cls_embeddings_np, init=\"pca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "y = train_claims['label_encoded']\n",
    "scatter = ax.scatter(claim_embedding_reduced[:, 0], claim_embedding_reduced[:, 1], cmap=\"Spectral\", c=y, s=0.6)\n",
    "\n",
    "encoded_to_label_map = {encoded: label for encoded, label in zip(train_claims[\"label_encoded\"].to_list(), train_claims[\"label\"].to_list())}\n",
    "handles, _ = scatter.legend_elements()\n",
    "legend_labels = [encoded_to_label_map[int(label)] for label in np.unique(y)]\n",
    "ax.legend(handles, legend_labels, title=\"Labels\", loc=\"best\", fontsize='small')\n",
    "\n",
    "# Add axis labels and title\n",
    "ax.set_title(\"Scatter Plot of Claim Embeddings\")\n",
    "ax.set_xlabel(\"Component 1\")\n",
    "ax.set_ylabel(\"Component 2\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "checkthat-numerical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
